from flask import Flask, request, jsonify
import spacy
from flask import Response
import json
import re
from langdetect import detect
import csv
import cv2
import numpy as np
import base64
import pytesseract
from googletrans import Translator
from spacy.language import Language
import unicodedata

# ÃncarcÄƒ modelul spaCy antrenat
nlp = spacy.load("model_ingrediente_best_with_diacritics3")

# IniÈ›ializeazÄƒ aplicaÈ›ia Flask
app = Flask(__name__)
#--------------------------------------------------------------------------------------------

def crop_image(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    data = pytesseract.image_to_data(gray, lang="ron", output_type=pytesseract.Output.DICT)
    x_min, y_min, x_max, y_max = np.inf, np.inf, 0, 0

    for i in range(len(data['text'])):
        if data['text'][i].strip() != "":
            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
            x_min = min(x_min, x)
            y_min = min(y_min, y)
            x_max = max(x_max, x + w)
            y_max = max(y_max, y + h)
    if x_max > x_min and y_max > y_min:
        cropped = img[y_min:y_max, x_min:x_max]
        return cropped
    else:
        return img  # fallback: returneazÄƒ originalul dacÄƒ nu detecteazÄƒ text

@app.route('/process-image', methods=['POST'])
def process_image():
    file = request.files['image']
    img_bytes = np.frombuffer(file.read(), np.uint8)
    img = cv2.imdecode(img_bytes, cv2.IMREAD_COLOR)

    cropped = crop_image(img)#  AplicÄƒm doar crop bazat pe text
    gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)

    _, buffer = cv2.imencode('.jpg', gray) # Encode Ã®napoi ca JPG
    img_base64 = base64.b64encode(buffer).decode('utf-8')
    return img_base64, 200
#--------------------------------------------------------------------------------------------
def normalize_text(text):
    # Ãnlocuim caractere strÄƒine asemÄƒnÄƒtoare cu diacriticele romÃ¢neÈ™ti, dar pÄƒstreazÄƒ ÄƒÃ®È™È›Ã¢.
    replacements = {
        'Ã ': 'a', 'Ã¡': 'a', 'Ã¢': 'a', 'Ã¤': 'a', 'Ä': 'a', 'Ã£': 'a', 'Ã¥': 'a', 'Ã¨': 'e', 'Ã©': 'e', 'Ãª': 'e', 'Ã«': 'e', 'Ä“': 'e', 'Ã¬': 'i', 'Ã­': 'i', 'Ã¯': 'i', 'Ã®': 'i', 'Ä«': 'i', 'Ã²': 'o', 'Ã³': 'o', 'Ã´': 'o', 'Ã¶': 'o', 'Ãµ': 'o', 'Å': 'o', 'Ã¹': 'u', 'Ãº': 'u', 'Ã»': 'u', 'Ã¼': 'u', 'Å«': 'u', 'Ã§': 'c', 'Ã±': 'n', 'Ã¿': 'y', 'Ä€': 'A', 'Ä’': 'E', 'Äª': 'I', 'ÅŒ': 'O', 'Åª': 'U', 'Ã¤': 'a', 'Ã«': 'e', 'Ã¯': 'i', 'Ã¶': 'o', 'Ã¼': 'u', 'Ã¿': 'y', 'È™': 'È™', 'È›': 'È›', 'Äƒ': 'Äƒ', 'Ã®': 'Ã®', 'Ã¢': 'Ã¢'  # pÄƒstrÄƒm diacriticele romÃ¢neÈ™ti
    }
    # Ãnlocuim caracterele strÄƒine È™i convertim la litere mici
    text_normalizat = ''.join(replacements.get(c, c) for c in text)
    return text_normalizat.lower()

def extrage_text_romana(text):
    text = normalize_text(text)
    # CautÄƒ secÈ›iunea care Ã®ncepe cu "Ingrediente:"
    pattern = re.compile(r"ingrediente:(.*?)(?=(?:[A-ZÄ‚ÃÈ˜Èš][a-zÄƒÃ®È™È›]+\s*:)|$)", re.DOTALL)
    match = pattern.search(text)
    if match:
        sectiune = match.group(1).strip()
        #return f"Ingrediente: {sectiune}"

    # DacÄƒ nu gÄƒseÈ™te "Ingrediente", aplicÄƒ detecÈ›ia de limbÄƒ
    propozitii = re.split(r'[.!?]', sectiune)
    propozitii_romana = []
    for prop in propozitii:
        prop_curata = prop.strip()
        if len(prop_curata) >= 20:  # ignorÄƒ fragmente scurte
            try:
                if detect(prop_curata) == "ro":
                    propozitii_romana.append(prop_curata)
            except:
                continue
    return " ".join(propozitii_romana) if propozitii_romana else text

@app.route('/extract_ingredients', methods=['POST'])
def extract_ingredients():
    data = request.get_json() # ObÈ›ine textul trimis de client (din JSON)
    if not data or 'text' not in data:
        return jsonify({'error': 'FurnizeazÄƒ cÃ¢mpul "text"'}), 400

    text = data['text']
    #print(text)
   
    text = extrage_text_romana(text) # Extrage doar porÈ›iunea relevantÄƒ
    print(text)
    doc = nlp(text)

    # Extrage entitÄƒÈ›ile
    ingredients = [ent.text for ent in doc.ents if ent.label_ == 'INGREDIENT']
    
    print("Ingredientele extrase sunt ", ingredients)

    return Response(
    json.dumps({"ingredients": ingredients}, ensure_ascii=False),
    content_type='application/json; charset=utf-8')

#--------------------------------------------------------------------------------------------
def normalize(text):
    if not isinstance(text, str):
        return ''
    text = text.lower().strip()
    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')  # eliminÄƒ diacritice
    text = re.sub(r'\s+', ' ', text)  # Ã®nlocuieÈ™te spaÈ›ii multiple cu unul singur
    return text

# ÃncarcÄƒ fiÈ™ierul CSV
def load_csv():
    drugs = {}
    with open('extracted_drug_data3.csv', mode='r', encoding='utf-8') as file:
        reader = csv.reader(file)
        next(reader)  # Sari peste header-ul CSV-ului
        for row in reader:
            name = normalize(row[0])
            food_interactions = row[1].strip()
            drugs[name] = food_interactions
            if 'lepirudina' in name:
                print(f"âœ” GÄƒsit Ã®n CSV: {name}")
    return drugs

drugs_data = load_csv()

# CreÄƒm un obiect Translator pentru Google Translate
translator = Translator()

# Traducerea textului din englezÄƒ Ã®n romÃ¢nÄƒ
def translate_text(text, src='en', dest='ro'):
    translation = translator.translate(text, src=src, dest=dest)
    return translation.text

# Preprocesare text pentru a adÄƒuga un spaÈ›iu dupÄƒ semnul punct È™i virgulÄƒ (dacÄƒ nu existÄƒ) si a scapa de articolele cuvintelor
def preprocess_text(text):
    # Ãnlocuim punctul È™i virgula urmat de un cuvÃ¢nt fÄƒrÄƒ spaÈ›iu cu punct È™i virgulÄƒ urmat de un spaÈ›iu
    text = text.replace(';', '; ')  # AdÄƒugÄƒm un spaÈ›iu dupÄƒ punct È™i virgulÄƒ
    text = re.sub(r'\b([a-zA-ZÄƒÃ®Ã¢È™È›]+)ul\b', r'\1', text)  # EliminÄƒm â€ulâ€ (articol definit la singular)
    text = re.sub(r'\b([a-zA-ZÄƒÃ®Ã¢È™È›]+)le\b', r'\1', text)  # EliminÄƒm â€leâ€ (articol definit la plural)    
    text = re.sub(r'(\.)([^\s])', r'. \2', text)  # DacÄƒ existÄƒ punct fÄƒrÄƒ spaÈ›iu, adÄƒugÄƒm spaÈ›iu
    return text

# Definim un sentencizer personalizat
# Decorator pentru a Ã®nregistra funcÈ›ia ca component spaCy
@Language.component("custom_sentencizer")
def custom_sentencizer(doc):
    for token in doc[:-1]:  # IterÄƒm prin toate token-urile din document
        if token.text == ";":  # DacÄƒ gÄƒsim punct È™i virgulÄƒ
            token.is_sent_start = True  # ConsiderÄƒm cÄƒ urmÄƒtorul token Ã®ncepe o propoziÈ›ie
        else:
            token.is_sent_start = False  # ContinuÄƒm propoziÈ›ia curentÄƒ
    return doc

# AdÄƒugÄƒm funcÈ›ia custom_sentencizer Ã®n pipeline-ul spaCy
nlp.add_pipe("custom_sentencizer", before='ner')  # AdÄƒugÄƒm 'custom_sentencizer' Ã®nainte de NER

@app.route('/get_food_interactions', methods=['POST'])

def get_food_interactions():
    data = request.get_json()
    medicamente = data.get('name', [])  # O listÄƒ de medicamente trimisÄƒ din Flutter
    ingrediente = data.get('ingrediente', [])  # Lista de ingrediente trimisÄƒ din Flutter
    
    alimente_evitate_totale = [] # IniÈ›ializÄƒm liste pentru rezultate
    alimente_recomandate_totale = []

    # IterÄƒm prin fiecare medicament din lista trimisÄƒ
    for medicament in medicamente:
        medicament = normalize(medicament)
        print(f"ğŸ”¸ Primit din Flutter: {medicament}")
        #medicament = medicament.strip().lower() 
        
        if medicament in drugs_data:
            food_interactions = drugs_data[medicament]
            print(f"InteracÈ›iuni alimentare pentru {medicament}: {food_interactions}")  # Log pentru a verifica interacÈ›iunile

            food_interactions_ro = translate_text(food_interactions, src='en', dest='ro') # Traducem textul din englezÄƒ Ã®n romÃ¢nÄƒ
            print(f"Textul alimentar in romana pentru {medicament}: {food_interactions_ro}") 

            food_interactions_ro = preprocess_text(food_interactions_ro.lower())  # ProcesÄƒm textul interacÈ›iunilor alimentare
            print(f"Textul alimentar in romana preprocesat pentru {medicament}: {food_interactions_ro}") 

            doc = nlp(food_interactions_ro) # AplicÄƒm modelul NER pe textul procesat

            alimente_evitate = [] # Liste pentru alimentele recomandate È™i evitate
            alimente_recomandate = []

            # IterÄƒm prin entitÄƒÈ›ile recunoscute
            for ent in doc.ents:
                if ent.label_ == "INGREDIENT":
                    ingredient = ent.text.lower()

                    # Extragem propoziÈ›ia Ã®n care apare ingredientul
                    sentence = ent.sent.text.lower()  # ObÈ›inem Ã®ntreaga propoziÈ›ie

                    # CÄƒutÄƒm cuvinte cheie pentru a determina dacÄƒ ingredientul este recomandat sau evitat
                    if "evitaÈ›i" in sentence or "limiteazÄƒ" in sentence:
                        alimente_evitate.append(ingredient)
                    elif "ia cu" in sentence or "administreazÄƒ" in sentence or "luaÈ›i cu" in sentence:
                        alimente_recomandate.append(ingredient)

            # AdÄƒugÄƒm rezultatele pentru fiecare medicament la listele totale
            alimente_evitate_totale.extend(alimente_evitate)
            alimente_recomandate_totale.extend(alimente_recomandate)

            print(f"Alimente recomandate pentru {medicament}: {alimente_recomandate}")
            print(f"Alimente evitate pentru {medicament}: {alimente_evitate}")

        else:
            print(f"Medicamentul {medicament} nu a fost gÄƒsit Ã®n baza de date.")

    # VerificÄƒm dacÄƒ vreun ingredient evitat se regÄƒseÈ™te Ã®n lista trimisÄƒ din Flutter
    alimente_evitate_gasite = [ingredient for ingredient in alimente_evitate_totale if ingredient in [i.lower() for i in ingrediente]]

    # ReturnÄƒm rezultatele pentru toate medicamentele
    return jsonify({
        'alimente_recomandate': alimente_recomandate_totale,
        'alimente_evitate': alimente_evitate_gasite
    })

# def get_food_interactions():
#     data = request.get_json()
#     medicamente = data.get('name', [])  # lista de medicamente trimisÄƒ din Flutter
#     ingrediente = data.get('ingrediente', [])  # Lista de ingrediente trimisÄƒ din Flutter
#     alimente_evitate_totale = [] # IniÈ›ializÄƒm liste pentru rezultate
#     alimente_recomandate_totale = []

#     for medicament in medicamente: # IterÄƒm prin fiecare medicament din lista trimisÄƒ
#         medicament = medicament.strip().lower() 
#         if medicament in drugs_data:
#             food_interactions = drugs_data[medicament]
#             food_interactions_ro = translate_text(food_interactions, src='en', dest='ro') # Traducem textul din englezÄƒ Ã®n romÃ¢nÄƒ
#             food_interactions_ro = preprocess_text(food_interactions_ro.lower())  # ProcesÄƒm textul interacÈ›iunilor alimentare
#             alimente_evitate = [] # Liste pentru alimentele recomandate È™i evitate
#             alimente_recomandate = []

#             doc = nlp(food_interactions_ro) # AplicÄƒm modelul NER pe textul procesat
#             for ent in doc.ents: # IterÄƒm prin entitÄƒÈ›ile recunoscute
#                 if ent.label_ == "INGREDIENT":
#                     ingredient = ent.text.lower()
#                     sentence = ent.sent.text.lower()  # Extragem propoziÈ›ia Ã®n care apare ingredientul
#                     # CÄƒutÄƒm cuvinte cheie pentru a determina dacÄƒ ingredientul este recomandat sau evitat
#                     if "evitaÈ›i" in sentence or "limiteazÄƒ" in sentence:
#                         alimente_evitate.append(ingredient)
#                     elif "ia cu" in sentence or "administreazÄƒ" in sentence or "luaÈ›i cu" in sentence:
#                         alimente_recomandate.append(ingredient)

#             alimente_evitate_totale.extend(alimente_evitate) # AdÄƒugÄƒm rezultatele pentru fiecare medicament la listele totale
#             alimente_recomandate_totale.extend(alimente_recomandate)
#         else:
#             print(f"Medicamentul {medicament} nu a fost gÄƒsit Ã®n baza de date.")
#     # VerificÄƒm dacÄƒ vreun ingredient evitat se regÄƒseÈ™te Ã®n lista trimisÄƒ din Flutter
#     alimente_evitate_gasite = [ingredient for ingredient in alimente_evitate_totale if ingredient in [i.lower() for i in ingrediente]]

#     return jsonify({
#         'alimente_recomandate': alimente_recomandate_totale,
#         'alimente_evitate': alimente_evitate_gasite
#     })
#--------------------------------------------------------------------------------------------
# Endpoint pentru a verifica dacÄƒ serverul funcÈ›ioneazÄƒ
@app.route('/test_connection', methods=['GET'])
def test_connection():
    return jsonify({'message': 'Conexiunea cu serverul este activÄƒ!'})

if __name__ == '__main__':
    app.run(debug=True)
